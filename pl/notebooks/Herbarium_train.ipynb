{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "412d3146-c3af-4c7e-8f70-625085de60a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pl/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms \n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "from pytorch_lightning.strategies import ParallelStrategy\n",
    "from pytorch_lightning.utilities.cli import LightningCLI\n",
    "from pytorch_lightning import Trainer\n",
    "# from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.plugins import DDPPlugin\n",
    "from torchmetrics import Accuracy, F1Score, Specificity\n",
    "\n",
    "import json\n",
    "import matplotlib.image as image \n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.dataset import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14dc2585-1b5e-426a-ac98-be73e07038a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb6dae5-f4b9-4f23-8ea8-2295311eadff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_dir</th>\n",
       "      <th>category</th>\n",
       "      <th>genus</th>\n",
       "      <th>institutions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000__001</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000__002</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000__003</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000__004</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000__005</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id                                          image_dir  category  \\\n",
       "0  00000__001  ../dataset/herbarium_2022/train_images/000/00/...         0   \n",
       "1  00000__002  ../dataset/herbarium_2022/train_images/000/00/...         0   \n",
       "2  00000__003  ../dataset/herbarium_2022/train_images/000/00/...         0   \n",
       "3  00000__004  ../dataset/herbarium_2022/train_images/000/00/...         0   \n",
       "4  00000__005  ../dataset/herbarium_2022/train_images/000/00/...         0   \n",
       "\n",
       "   genus  institutions  \n",
       "0  Abies             0  \n",
       "1  Abies             0  \n",
       "2  Abies             0  \n",
       "3  Abies             0  \n",
       "4  Abies             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6b3c766-0473-4517-aa1e-66c4f3ff6ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(839772, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae37de56-4b44-4173-8f6e-767494da4b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15501\n",
      "2564\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "print(len(df.category.unique()))\n",
    "print(len(df.genus.unique()))\n",
    "print(len(df.institutions.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a106765f-70ce-42b9-84c3-b41f1cdeeb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_dir</th>\n",
       "      <th>category</th>\n",
       "      <th>genus</th>\n",
       "      <th>institutions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000__001</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000__002</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000__003</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000__004</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000__005</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id                                          image_dir  category  \\\n",
       "0  00000__001  ../dataset/herbarium_2022/train_images/000/00/...         0   \n",
       "1  00000__002  ../dataset/herbarium_2022/train_images/000/00/...         0   \n",
       "2  00000__003  ../dataset/herbarium_2022/train_images/000/00/...         0   \n",
       "3  00000__004  ../dataset/herbarium_2022/train_images/000/00/...         0   \n",
       "4  00000__005  ../dataset/herbarium_2022/train_images/000/00/...         0   \n",
       "\n",
       "   genus  institutions  \n",
       "0  Abies             0  \n",
       "1  Abies             0  \n",
       "2  Abies             0  \n",
       "3  Abies             0  \n",
       "4  Abies             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(inplace=True, drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb95ef97-4538-4b08-9cdd-f369d2dc35b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df.category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3533a00-2b1f-4720-8798-32ec30296107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd90b53b-978d-4ae6-9c11-b9592aeefdf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab3916b1-4324-470a-bb2d-66189d6a2a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HerbClsModel(LightningModule) :\n",
    "    def __init__(\n",
    "        self,\n",
    "        arch: str = 'resnet18',\n",
    "        pretrained: bool = False,\n",
    "        lr: float = 0.9,\n",
    "        momentum: float = 0.9,\n",
    "        weight_decay: float = 1e-4,\n",
    "        batch_size: int =256,\n",
    "        workers: int = 4,\n",
    "        num_classes: int = 5,\n",
    "        from_contra : str = './saved_models/contra/',\n",
    "        # is_contra: bool = False,\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.arch = arch\n",
    "        self.pretrained = pretrained\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.weight_decay = weight_decay\n",
    "        self.batch_size = batch_size\n",
    "        self.workers = workers\n",
    "        self.num_classes = num_classes\n",
    "        self.from_contra = from_contra\n",
    "        \n",
    "        if self.arch not in models.__dict__.keys() : \n",
    "            # self.model = custom_models.__dict__[self.arch](pretrained=False, img_size=args.img_size)\n",
    "            self.model = custom_models.__dict__[self.arch](pretrained=False)\n",
    "        else :\n",
    "            print('only resnet is supported') \n",
    "            self.model = models.__dict__[self.arch](pretrained=self.pretrained) \n",
    "        \n",
    "        shape = self.model.fc.weight.shape\n",
    "        self.model.fc = nn.Linear(shape[1], self.num_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "            \n",
    "        print(\"=> creating model '{}'\".format(self.arch))\n",
    "        self.train_acc1 = Accuracy(top_k=1)\n",
    "        self.eval_acc1 = Accuracy(top_k=1)\n",
    "        self.f1 = F1Score(average='macro', num_classes=self.num_classes)\n",
    "        self.specificity = Specificity(average='macro', num_classes=self.num_classes)\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx) :\n",
    "        images, targets = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, targets)\n",
    "        correct=outputs.argmax(dim=1).eq(targets).sum().item()\n",
    "        total=len(targets)\n",
    "        \n",
    "        #update metric\n",
    "        self.log('train_loss', loss)\n",
    "        self.train_acc1(outputs, targets)\n",
    "        self.log('train_acc', self.train_acc1, prog_bar=True)\n",
    "        \n",
    "        #for tensorboard\n",
    "        logs={\"train_loss\": loss}\n",
    "        batch_dictionary={\n",
    "            'loss':loss,\n",
    "            'log':logs,\n",
    "            # info to be used at epoch end\n",
    "            \"correct\": correct,\n",
    "            \"total\": total\n",
    "        }        \n",
    "        \n",
    "        return batch_dictionary\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        # if(self.current_epoch==1):\n",
    "        #     sampleImg=torch.rand((1,3,IMAGE_SIZE,IMAGE_SIZE))\n",
    "        #     self.logger.experiment.add_graph(self.model(), sampleImg)\n",
    "\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        \n",
    "        # logging histograms\n",
    "        # self.custom_histogram_adder()\n",
    "        \n",
    "        # calculating correect and total predictions\n",
    "        correct=sum([x[\"correct\"] for  x in outputs])\n",
    "        total=sum([x[\"total\"] for  x in outputs])\n",
    "        \n",
    "        # creating log dictionary\n",
    "        # self.logger.experiment.add_scalar('loss/train', avg_loss, self.current_epoch)\n",
    "        # self.logger.experiment.add_scalar('acc/train', correct/total, self.current_epoch)\n",
    "        tensorboard_logs = {'loss': avg_loss, \"Accuracy\": correct/total}\n",
    "        \n",
    "        epoch_dictionary={\n",
    "            # required\n",
    "            'loss': avg_loss,\n",
    "            # for logging purposes\n",
    "            'log': tensorboard_logs\n",
    "        }\n",
    " \n",
    "        # wandb expect None\n",
    "        # return epoch_dictionary  \n",
    "\n",
    "    def custom_histogram_adder(self):\n",
    "        for name, params in self.named_parameters():\n",
    "            self.logger.experiment.add_histogram(name, params, self.current_epoch)\n",
    "    \n",
    "    def eval_step(self, batch, batch_idx, prefix: str) :\n",
    "        images, targets = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, targets)\n",
    "        \n",
    "        self.log(f'{prefix}_loss', loss)\n",
    "        self.eval_acc1(outputs, targets)\n",
    "        self.log(f'{prefix}_acc1', self.eval_acc1, prog_bar=True)\n",
    "        self.f1(outputs, targets)\n",
    "        self.log(f'{prefix}_f1_score', self.f1, prog_bar=True)\n",
    "        self.specificity(outputs, targets)\n",
    "        self.log(f'{prefix}_specificity', self.specificity, prog_bar=True)    \n",
    "        \n",
    "        if prefix == 'val' :\n",
    "            correct=outputs.argmax(dim=1).eq(targets).sum().item()\n",
    "            total=len(targets) \n",
    "            \n",
    "            #for tensorboard\n",
    "            logs={\"val_loss\": loss}\n",
    "            batch_dictionary={\n",
    "                'loss':loss,\n",
    "                'log':logs,\n",
    "                # info to be used at epoch end\n",
    "                \"correct\": correct,\n",
    "                \"total\": total\n",
    "            }  \n",
    "            \n",
    "            return batch_dictionary\n",
    "\n",
    "        return loss            \n",
    "        \n",
    "    def validation_step(self, batch, batch_idx) :\n",
    "        return self.eval_step(batch, batch_idx, 'val')\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        \n",
    "        # calculating correect and total predictions\n",
    "        correct=sum([x[\"correct\"] for  x in outputs])\n",
    "        total=sum([x[\"total\"] for  x in outputs])\n",
    "        \n",
    "        tensorboard_logs = {'loss': avg_loss, \"Accuracy\": correct/total}\n",
    "        \n",
    "        epoch_dictionary={\n",
    "            # required\n",
    "            'loss': avg_loss,\n",
    "            # for logging purposes\n",
    "            'log': tensorboard_logs\n",
    "        }\n",
    "        \n",
    "        # wandb expect None\n",
    "        # return epoch_dictionary    \n",
    "\n",
    "    def test_step(self, batch, batch_idx) :\n",
    "        return self.eval_step(batch, batch_idx, 'test')\n",
    "    \n",
    "    def configure_optimizers(self) :\n",
    "        optimizer = optim.SGD(filter(lambda p: p.requires_grad, self.parameters()), \n",
    "                              lr=self.lr, momentum=self.momentum, weight_decay=self.weight_decay)\n",
    "        \n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lambda epoch : 0.1 **(epoch //30))\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "#     load contra checkpoint in fine tuning\n",
    "    def load_contra_checkpoint(self, path):\n",
    "        state_dict = torch.load(path)['state_dict']\n",
    "        model_state_dict = self.state_dict()\n",
    "        for k in state_dict:\n",
    "            if k in model_state_dict:\n",
    "                if state_dict[k].shape != model_state_dict[k].shape:\n",
    "                    print(f\"Skip loading parameter: {k}, \"\n",
    "                                f\"required shape: {model_state_dict[k].shape}, \"\n",
    "                                f\"loaded shape: {state_dict[k].shape}\")\n",
    "                    state_dict[k] = model_state_dict[k]\n",
    "\n",
    "            else:\n",
    "                print(f\"Dropping parameter {k}\")\n",
    "\n",
    "        self.load_state_dict(state_dict)\n",
    "        \n",
    "#     model freezing when fine tuning( linear evaluation protocol)\n",
    "    def model_freeze(self) :\n",
    "        for param in self.parameters( ) :\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.model.fc.weight.requires_grad = True\n",
    "        self.model.fc.bias.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52107473-9fdf-405b-98ff-776c85509d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_dir</th>\n",
       "      <th>category</th>\n",
       "      <th>genus</th>\n",
       "      <th>institutions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000__001</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000__002</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000__003</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000__004</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000__005</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id                                          image_dir  category  \\\n",
       "0  00000__001  ../dataset/herbarium_2022/train_images/000/00/...         0   \n",
       "1  00000__002  ../dataset/herbarium_2022/train_images/000/00/...         0   \n",
       "2  00000__003  ../dataset/herbarium_2022/train_images/000/00/...         0   \n",
       "3  00000__004  ../dataset/herbarium_2022/train_images/000/00/...         0   \n",
       "4  00000__005  ../dataset/herbarium_2022/train_images/000/00/...         0   \n",
       "\n",
       "   genus  institutions  \n",
       "0  Abies             0  \n",
       "1  Abies             0  \n",
       "2  Abies             0  \n",
       "3  Abies             0  \n",
       "4  Abies             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "735a2dc5-fa4e-47f3-be47-b502a2f4a0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[10, 'category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c77d469-89db-49d4-8951-db53d5299827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_dir</th>\n",
       "      <th>category</th>\n",
       "      <th>genus</th>\n",
       "      <th>institutions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>00000__001</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>00000__002</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>00000__003</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>00000__004</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>00000__005</td>\n",
       "      <td>../dataset/herbarium_2022/train_images/000/00/...</td>\n",
       "      <td>0</td>\n",
       "      <td>Abies</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    image_id                                          image_dir  \\\n",
       "0      0  00000__001  ../dataset/herbarium_2022/train_images/000/00/...   \n",
       "1      1  00000__002  ../dataset/herbarium_2022/train_images/000/00/...   \n",
       "2      2  00000__003  ../dataset/herbarium_2022/train_images/000/00/...   \n",
       "3      3  00000__004  ../dataset/herbarium_2022/train_images/000/00/...   \n",
       "4      4  00000__005  ../dataset/herbarium_2022/train_images/000/00/...   \n",
       "\n",
       "   category  genus  institutions  \n",
       "0         0  Abies             0  \n",
       "1         0  Abies             0  \n",
       "2         0  Abies             0  \n",
       "3         0  Abies             0  \n",
       "4         0  Abies             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76959778-5bc7-4202-9344-cf4f90a773ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(839772, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pl/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:95: LightningDeprecationWarning: DataModule property `train_transforms` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "/home/beomgon/anaconda3/envs/pl/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:133: LightningDeprecationWarning: DataModule property `test_transforms` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "dm = HerbDataModule(df, batch_size, transform=train_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea2e6c-6d1d-4d83-9672-2c284645680d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only resnet is supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pl/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'resnet18'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pl/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:88: LightningDeprecationWarning: DataModule property `train_transforms` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "/home/beomgon/anaconda3/envs/pl/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:126: LightningDeprecationWarning: DataModule property `test_transforms` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(629829, 7)\n",
      "(209943, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | model       | ResNet           | 19.1 M\n",
      "1 | criterion   | CrossEntropyLoss | 0     \n",
      "2 | train_acc1  | Accuracy         | 0     \n",
      "3 | eval_acc1   | Accuracy         | 0     \n",
      "4 | f1          | F1Score          | 0     \n",
      "5 | specificity | Specificity      | 0     \n",
      "-------------------------------------------------\n",
      "19.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "19.1 M    Total params\n",
      "76.514    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pl/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pl/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 40/26244 [00:45<8:21:48,  1.15s/it, loss=9.7, v_num=5, train_acc=0.000] "
     ]
    }
   ],
   "source": [
    "num_classes = len(df.category.unique())\n",
    "model = HerbClsModel(pretrained=True, num_classes=num_classes)\n",
    "\n",
    "devices = torch.cuda.device_count()\n",
    "trainer = Trainer(\n",
    "    max_epochs=3,\n",
    "    progress_bar_refresh_rate=20,\n",
    "    # gpus=devices,\n",
    "    gpus=1,\n",
    "    # strategy = \"ddp\",\n",
    ")\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63491f-5fc3-41ba-9668-7880bce21175",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7688f6c9-1523-4366-921d-1318869f3a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d575580-e861-4faf-9c14-e1eb86b3b4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95251bb5-5a22-4b16-8824-6d606781f0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaed043f-b542-4dbb-a0e1-7a6379281477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e04c2-a003-465c-b124-172ec2bfa68c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8cdc53-9f23-4eb5-ab0d-adc8870667e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e221b3-74b7-494c-bf4b-c7d2b6670b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc111a7a-0ac1-461a-968a-45ad8fc10787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efb351d-b80b-4871-aefe-b3a49e344398",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl",
   "language": "python",
   "name": "pl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
